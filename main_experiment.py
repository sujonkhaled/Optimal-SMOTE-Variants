# -*- coding: utf-8 -*-
"""main_experiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nrHdHOVvbCAd6CrDa7e8Q8Qt-3oftlk7
"""

# we have imported all required packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN
from imblearn.combine import SMOTETomek
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix

# we have uploaded our selected AI course Dataset collected from UTM

data = pd.read_csv("AI course Dataset.csv")
enc = LabelEncoder()
data['Grade'] = enc.fit_transform(data['Grade'])
data['Categories'] = enc.fit_transform(data['Categories'])
original_categories = enc.inverse_transform(range(len(enc.classes_)))
X = data.drop(columns=['Categories'])
y = data['Categories']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
smote_variants = {
    'Standard SMOTE': SMOTE(k_neighbors=1, random_state=42),
    'Borderline-SMOTE': BorderlineSMOTE(k_neighbors=1, random_state=42),
    'SMOTE-Tomek': SMOTETomek(smote=SMOTE(k_neighbors=1, random_state=42), random_state=42),
    'ADASYN': ADASYN(n_neighbors=1, random_state=42)
}
resampled_data = {}
for variant, sampler in smote_variants.items():
    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)
    resampled_data[variant] = (X_resampled, y_resampled)
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, C=1.0, solver='lbfgs'),
    'Random Forest': RandomForestClassifier(n_estimators=10, max_depth=2, random_state=42, min_samples_split=2, criterion='gini'),
    'XGBoost': XGBClassifier(n_estimators=10, max_depth=1, learning_rate=0.05, eval_metric='logloss', random_state=42, subsample=0.8, colsample_bytree=0.8),
    'AdaBoost': AdaBoostClassifier(n_estimators=10, learning_rate=0.05, random_state=42)
}
def calculate_metrics(y_true, y_pred, y_prob):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')
    roc_auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')
    return accuracy, precision, recall, f1, roc_auc
results = {
    'Model': [],
    'SMOTE Variant': [],
    'Accuracy': [],
    'Precision': [],
    'Recall': [],
    'F1 Score': [],
    'ROC AUC': []
}
for model_name, model in models.items():
    y_pred = cross_val_predict(model, X_train, y_train, cv=5, method='predict')
    y_prob = cross_val_predict(model, X_train, y_train, cv=5, method='predict_proba')
    accuracy, precision, recall, f1, roc_auc = calculate_metrics(y_train, y_pred, y_prob)
    results['Model'].append(model_name)
    results['SMOTE Variant'].append('Original')
    results['Accuracy'].append(accuracy)
    results['Precision'].append(precision)
    results['Recall'].append(recall)
    results['F1 Score'].append(f1)
    results['ROC AUC'].append(roc_auc)
for variant, (X_resampled, y_resampled) in resampled_data.items():
    for model_name, model in models.items():
        y_pred = cross_val_predict(model, X_resampled, y_resampled, cv=5, method='predict')
        y_prob = cross_val_predict(model, X_resampled, y_resampled, cv=5, method='predict_proba')
        accuracy, precision, recall, f1, roc_auc = calculate_metrics(y_resampled, y_pred, y_prob)
        results['Model'].append(model_name)
        results['SMOTE Variant'].append(variant)
        results['Accuracy'].append(accuracy)
        results['Precision'].append(precision)
        results['Recall'].append(recall)
        results['F1 Score'].append(f1)
        results['ROC AUC'].append(roc_auc)
results_df = pd.DataFrame(results)
def plot_confusion_matrix(cm, title, labels):
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(title)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.show()
for variant, (X_resampled, y_resampled) in resampled_data.items():
    for model_name, model in models.items():
        model.fit(X_resampled, y_resampled)
        y_pred = model.predict(X_test)
        cm = confusion_matrix(y_test, y_pred)
        plot_confusion_matrix(cm, f'{variant} ({model_name})', labels=enc.classes_)
plt.figure(figsize=(12, 8))
sns.heatmap(results_df.pivot(index="SMOTE Variant", columns="Model", values="Accuracy"), annot=True, cmap='YlGnBu', fmt='.3f')
plt.title('Accuracy Heatmap')
plt.show()
plt.figure(figsize=(12, 8))
sns.heatmap(results_df.pivot(index="SMOTE Variant", columns="Model", values="Precision"), annot=True, cmap='YlGnBu', fmt='.3f')
plt.title('Precision Heatmap')
plt.show()
plt.figure(figsize=(12, 8))
sns.heatmap(results_df.pivot(index="SMOTE Variant", columns="Model", values="Recall"), annot=True, cmap='YlGnBu', fmt='.3f')
plt.title('Recall Heatmap')
plt.show()
plt.figure(figsize=(12, 8))
sns.heatmap(results_df.pivot(index="SMOTE Variant", columns="Model", values="F1 Score"), annot=True, cmap='YlGnBu', fmt='.3f')
plt.title('F1 Score Heatmap')
plt.show()
plt.figure(figsize=(12, 8))
for variant, (X_resampled, y_resampled) in resampled_data.items():
    for model_name, model in models.items():
        model.fit(X_resampled, y_resampled)
        y_prob = model.predict_proba(X_test)
        fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1], pos_label=1)
        plt.plot(fpr, tpr, label=f'{variant} ({model_name})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
plt.figure(figsize=(12, 8))
for variant, (X_resampled, y_resampled) in resampled_data.items():
    for model_name, model in models.items():
        model.fit(X_resampled, y_resampled)
        y_prob = model.predict_proba(X_test)
        precision, recall, _ = precision_recall_curve(y_test, y_prob[:, 1], pos_label=1)
        plt.plot(recall, precision, label=f'{variant} ({model_name})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']
for metric in metrics:
    plt.figure(figsize=(12, 8))
    sns.boxplot(x='SMOTE Variant', y=metric, data=results_df)
    plt.title(f'{metric} Box Plot')
    plt.show()
for metric in metrics:
    plt.figure(figsize=(12, 8))
    sns.barplot(x='SMOTE Variant', y=metric, hue='Model', data=results_df)
    plt.title(f'{metric} Bar Chart')
    plt.legend(loc='upper right')
    plt.show()